# install.packages("gmodels")
library(gmodels)
library(class)

Absent <- read.csv("Absenteeism.csv",
                 stringsAsFactors = FALSE)
# drop the id feature
Absent$id <- NULL
# table of diagnosis
table(Absent$diagnosis)
# recode diagnosis as a factor
Absent$diagnosis <- factor(Absent$diagnosis,
                         levels = c("W", "H"),
                         labels = c("Weight", "Height"))

# table or proportions with more informative labels
prop.table(table(Absent$diagnosis))
# summarize three numeric features
summary(Absent[c("Weight", "Height")])
# create normalization function
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
# test normalization function - result should be identical
normalize(c(1, 2, 3, 4, 5))
normalize(c(10, 20, 30, 40, 50))

# normalize the wbcd data
# note doesnâ€™t include the labels
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
# confirm that normalization worked
summary(wbcd_n$area_mean)
# create training and test data (no labels)
wbcd_train <- wbcd_n[1:469, ]
wbcd_test <- wbcd_n[470:569, ]
# create labels for training and test data
wbcd_train_labels <- wbcd[1:469, 1]
wbcd_test_labels <- wbcd[470:569, 1]

## Step 3: Training a model on the data ----
predictions <- knn(train = wbcd_train, test =
                     wbcd_test, cl = wbcd_train_labels, k=21)
## Step 4: Evaluating model performance ----
# load the "gmodels" library
install.packages("gmodels")
library(gmodels)
# Create the cross tabulation of predicted vs. actual
CrossTable(predictions, wbcd_test_labels,
           prop.chisq = FALSE,
           prop.c = FALSE, prop.r = FALSE)